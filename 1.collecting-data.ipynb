{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Here we are requesting an API\n",
    "response = requests.get(\"http://api.open-notify.org/astros.json\").json()\n",
    "\n",
    "# Here we are making a loop\n",
    "for astronaut in response[\"people\"]:\n",
    "    print(astronaut[\"name\"],\"is in\",astronaut[\"craft\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data collection\n",
    "\n",
    "The goal of this presentation is to automate data collection.\n",
    "We need some historical data to build our model and predict electrical consumption in Paris for J+1.   \n",
    "Basically we need to collect as much interesting data as possible, starting from nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Expected output\n",
    "\n",
    "Datasets saved on our computer with file formats easily readable by python : csv, json, xml, excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizz (5 minutes) : What kind of data might be interesting to make a prediction ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workshop (15 minutes) : Try to collect the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Easy : Historical electrical consumption\n",
    "\n",
    "[Electrical consumption in île-de-France between 2013 and 2017](https://rte-opendata.opendatasoft.com/explore/dataset/eco2mix_regional_cons_def/export/?disjunctive.libelle_region&disjunctive.nature&sort=-date_heure&refine.libelle_region=Ile-de-France)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption = pd.read_csv(\"./data/eco2mix_regional_cons_def.csv\", delimiter=\";\",parse_dates=[\"Date - Heure\"])\n",
    "consumption.set_index('Date - Heure',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption.sort_index(inplace=True)\n",
    "consumption.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample = consumption.resample('D').count()\n",
    "resample[resample[\"Code INSEE région\"]<48]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less easy : Historical weather\n",
    "\n",
    "Not enough data : [Prévision Météo - Paris - AROME](https://public.opendatasoft.com/explore/dataset/arome-0025-sp1_sp2_paris/export/)  \n",
    "Let's pay for some data ! [Openweather map API](https://openweathermap.org/history-bulk) (10$ for 5 years of weather in paris : a bargain !)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"./data/meteo-paris.csv\")\n",
    "weather['dt'] = pd.to_datetime(weather['dt'],unit='s')\n",
    "weather.set_index('dt',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather.index.min())\n",
    "print(weather.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample = weather.resample('D').count()\n",
    "resample.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Days off in France\n",
    "\n",
    "No dataset easily available, we are going to scrap the web :\n",
    "https://www.calendrier-365.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "days_off = []\n",
    "for year in range(2012,2020):\n",
    "    url = 'https://www.calendrier-365.fr/jours-feries/{}.html'.format(year)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text,\"lxml\")\n",
    "    for x in soup.find_all(\"td\", {\"class\":\"dtr tar\"}):\n",
    "        date = datetime.fromtimestamp(int(x.attrs[\"data-value\"]))\n",
    "        days_off.append(date.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_day_off(date):\n",
    "    \"\"\"\n",
    "    Function to tell if a day is off in France\n",
    "    Only works from 2013 to 2020.\n",
    "    \"\"\"\n",
    "    if date.strftime(\"%Y-%m-%d\") in days_off:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "today = datetime.datetime.today() \n",
    "\n",
    "next_saturday = today + datetime.timedelta(days=2)\n",
    "christmas = datetime.datetime(2018,12,25)\n",
    "easter = datetime.datetime(2015,4,5)\n",
    "\n",
    "print(is_day_off(next_saturday))\n",
    "print(is_day_off(today))\n",
    "print(is_day_off(christmas))\n",
    "print(is_day_off(easter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strikes in Paris\n",
    "Copyright to William Revah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "strikes = []\n",
    "\n",
    "url = \"https://fr.wikipedia.org/wiki/Liste_des_manifestations_les_plus_importantes_en_France\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text,\"lxml\")\n",
    "for table in soup.find_all(\"table\"):\n",
    "    for x in table.find_all(\"tr\"):\n",
    "        date=x.find_next(\"time\")\n",
    "        strikes.append(date.attrs[\"datetime\"])\n",
    "\n",
    "print(strikes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
