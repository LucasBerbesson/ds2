{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning / Wrangling\n",
    "\n",
    "**Goal** : gather all the data in one clean csv file\n",
    "\n",
    "\n",
    "## Step 1 : Consumptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"./data/eco2mix_regional_cons_def.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the table\n",
    "print(\"Shape\", df1.shape)\n",
    "print(\"Columns\", df1.columns)\n",
    "df1.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only interesting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column types if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have duplicated dates with different consumptions, **interesting** !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check days with missing half hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have days with less that 48 half hours, **interesting** !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"./data/meteo-paris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Merge everything together\n",
    "\n",
    "[Documentation on how to merge with pandas](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html)\n",
    "\n",
    "\n",
    "![How to merge](https://shanelynnwebsite-mid9n9g1q9y8tt.netdna-ssl.com/wp-content/uploads/2017/03/join-types-merge-names.jpg)\n",
    "\n",
    "\n",
    "**Inner Merge / Inner join** – The default Pandas behaviour, only keep rows where the merge “on” value exists in both the left and right dataframes.\n",
    "\n",
    "**Left Merge / Left outer join** – Keep every row in the left dataframe. Where there are missing values of the “on” variable in the right dataframe, add empty / NaN values in the result.\n",
    "\n",
    "**Right Merge / Right outer join** – Keep every row in the right dataframe. Where there are missing values of the “on” variable in the left column, add empty / NaN values in the result.\n",
    "\n",
    "**Outer Merge / Full outer join** – A full outer join returns all the rows from the left dataframe, all the rows from the right dataframe, and matches up rows where possible, with NaNs elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 : handle missing half hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 : interpolate missing values\n",
    "We want to keep our historical consumptions (which are precious) so we will interpolate missing values for temperature\n",
    "\n",
    "First question : where are missing values ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 : Automate everything : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(consumption_csv=\"./data/eco2mix_regional_cons_def.csv\",weather_csv=\"./data/meteo-paris.csv\"):\n",
    "    \"\"\"\n",
    "    A function to get consumption and weather data\n",
    "    Do the wrangling\n",
    "    And return a nice & compact dataframe\n",
    "    Temperatures are in °C\n",
    "    \n",
    "    \"\"\"\n",
    "    # consumptions\n",
    "    consumption =  pd.read_csv(consumption_csv, delimiter=\";\", usecols = [\"Date - Heure\",\"Consommation (MW)\"])\n",
    "    consumption[\"Date - Heure\"] = pd.to_datetime(consumption[\"Date - Heure\"], utc=True).dt.tz_convert('Europe/Paris').dt.tz_localize(None)\n",
    "    consumption.drop_duplicates(inplace=True,subset='Date - Heure')\n",
    "    consumption.columns = ['Date', 'Conso']\n",
    "    # weather\n",
    "    weather = pd.read_csv(weather_csv,usecols=['dt','temp'])\n",
    "    weather.columns = ['Date', 'Temp']\n",
    "    weather.drop_duplicates(inplace=True,subset='Date')\n",
    "    weather['Date'] = pd.to_datetime(weather['Date'],unit='s',utc=True).dt.tz_convert('Europe/Paris').dt.tz_localize(None)    \n",
    "    # Merging\n",
    "    df1 = pd.merge(consumption,weather,on='Date',how=\"left\")\n",
    "    df1[\"Temp\"] = df1[\"Temp\"] - 273.15\n",
    "    # Half hours\n",
    "    date_range = pd.date_range(start=df1['Date'].min(),end=df1['Date'].max(),freq='30min')\n",
    "    half_hours = pd.DataFrame(date_range,columns=['Date'])\n",
    "    df2 = pd.merge(half_hours,df1,on='Date',how=\"left\")\n",
    "    #Interpolation\n",
    "    df2.interpolate('linear',limit=4,inplace=True)\n",
    "    return df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Conso']['2014':'2018'].plot(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Temp']['2014':'2018'].plot(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.distplot(df['Conso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's Clean !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
