{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning / Wrangling\n",
    "\n",
    "**Goal** : gather all the data in one clean csv file\n",
    "\n",
    "\n",
    "## Step 1 : get consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./data/eco2mix_regional_cons_def.csv\", delimiter=\";\",parse_dates=[\"Date - Heure\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption = df1[[\"Date - Heure\",\"Consommation (MW)\"]].copy().sort_values(by=['Date - Heure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicates\n",
    "# Identical dates\n",
    "print(consumption.duplicated(subset='Date - Heure').sum())\n",
    "# Identical dates and conso\n",
    "print(consumption.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have duplicated dates with different consumptions, **interesting** !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "consumption.drop_duplicates(inplace=True, subset='Date - Heure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "consumption.columns = ['Date', 'Conso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check days with missing half hours\n",
    "count_half_hours = consumption.set_index('Date').resample('D').count()\n",
    "count_half_hours[count_half_hours['Conso'] != 48]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have days with less that 48 half hours, **interesting** !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : get all half hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "\n",
    "print(consumption['Date'].min())\n",
    "print(consumption['Date'].max())\n",
    "\n",
    "dates = []\n",
    "dt = consumption['Date'].min()\n",
    "\n",
    "for i in range(90000):\n",
    "    dt += timedelta(minutes=30)\n",
    "    dates.append(dt)\n",
    "    \n",
    "half_hours = pd.DataFrame( half_hours,columns=['Date'])\n",
    "\n",
    "urs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start=consumption['Date'].min(),end=consumption['Date'].max(),freq='30min')\n",
    "half_hours = pd.DataFrame(date_range,columns=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : get temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"./data/meteo-paris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['dt'] = pd.to_datetime(df2['dt'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = df2[['dt','temp']].copy()\n",
    "weather.columns = ['Date', 'Temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicates\n",
    "weather.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "weather.drop_duplicates(inplace=True,subset='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Merge everything together\n",
    "\n",
    "[Documentation on how to merge with pandas](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html)\n",
    "\n",
    "\n",
    "![How to merge](https://shanelynnwebsite-mid9n9g1q9y8tt.netdna-ssl.com/wp-content/uploads/2017/03/join-types-merge-names.jpg)\n",
    "\n",
    "\n",
    "**Inner Merge / Inner join** – The default Pandas behaviour, only keep rows where the merge “on” value exists in both the left and right dataframes.\n",
    "\n",
    "**Left Merge / Left outer join** – Keep every row in the left dataframe. Where there are missing values of the “on” variable in the right dataframe, add empty / NaN values in the result.\n",
    "\n",
    "**Right Merge / Right outer join** – Keep every row in the right dataframe. Where there are missing values of the “on” variable in the left column, add empty / NaN values in the result.\n",
    "\n",
    "**Outer Merge / Full outer join** – A full outer join returns all the rows from the left dataframe, all the rows from the right dataframe, and matches up rows where possible, with NaNs elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge consumption and weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Consumption shape\",consumption.shape)\n",
    "print(\"Weather shape\",weather.shape)\n",
    "\n",
    "leftmerge = pd.merge(consumption,weather,on='Date',how=\"left\")\n",
    "innermerge = pd.merge(consumption,weather,on='Date',how=\"inner\")\n",
    "\n",
    "print(\"Left merge\", leftmerge.shape)\n",
    "print(\"Inner merge\", innermerge.shape)\n",
    "leftmerge.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(half_hours,leftmerge,on='Date',how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Date',inplace=True)\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 : interpolate missing temperatures\n",
    "We want to keep our historical consumptions (which are precious) so we will interpolate missing values for temperature\n",
    "\n",
    "First question : where are missing values ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.interpolate('linear',limit=4,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:'2017-12-05'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 : Automate everything : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(consumption_csv=\"./data/eco2mix_regional_cons_def.csv\",weather_csv=\"./data/meteo-paris.csv\"):\n",
    "    \"\"\"\n",
    "    A function to get consumption and weather data\n",
    "    Do the wrangling\n",
    "    And return a nice & compact dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    # consumptions\n",
    "    consumption =  pd.read_csv(consumption_csv, delimiter=\";\",parse_dates=[\"Date - Heure\"], usecols = [\"Date - Heure\",\"Consommation (MW)\"])\n",
    "    consumption.drop_duplicates(inplace=True,subset='Date - Heure')\n",
    "    consumption.columns = ['Date', 'Conso']\n",
    "    # half hours\n",
    "    start_date = consumption['Date'].min()\n",
    "    dates = []\n",
    "    for i in range(90000):\n",
    "        start_date += timedelta(minutes=30)\n",
    "        dates.append(start_date)\n",
    "    half_hours = pd.DataFrame(dates,columns=['Date'])\n",
    "    # weather\n",
    "    weather = pd.read_csv(weather_csv,usecols=['dt','temp'])\n",
    "    weather['dt'] = pd.to_datetime(weather['dt'],unit='s')\n",
    "    weather.columns = ['Date', 'Temp']\n",
    "    weather.drop_duplicates(inplace=True,subset='Date')\n",
    "    # Merging\n",
    "    df1 = pd.merge(consumption,weather,on='Date',how=\"left\")\n",
    "    df2 = pd.merge(half_hours,df1,on='Date',how=\"left\")\n",
    "    df2.interpolate('linear',limit=4,inplace=True)\n",
    "    df2[\"Temp\"] = df2[\"Temp\"] - 273.15\n",
    "    return df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(get_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_half_hours = df.set_index('Date').resample('D').count()\n",
    "count_half_hours[count_half_hours['Conso'] != 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's Clean !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
